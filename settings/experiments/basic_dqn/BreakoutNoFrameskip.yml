mlflow:
  experiment: "BreakoutNoFrameskip"
  url: "http://127.0.0.1:9999"
  user: "User"
dqn:
  env: BreakoutNoFrameskip
  run: DQN
  hyper_parameters:
    double_q: false
    dueling: false
    num_atoms: 1
    noisy: false
    n_step: 1
    lr: .0000625
    adam_epsilon: .00015
    hiddens: [ 512 ]
    num_steps_sampled_before_learning_starts: 20000
    # Extra
    num_gpus: 1
    framework: "torch"
    evaluation_duration_unit: "episodes"
    # DQN
    num_envs_per_worker: 1
    num_gpus_per_worker: 0
    train_batch_size: 512
    target_network_update_freq: 8000
    min_sample_timesteps_per_iteration: 10000
    replay_buffer_config:
      type: 'ReplayBuffer'
      capacity: 1000000
      prioritized_replay_beta: 1
      prioritized_replay_alpha: 0.5
log:
  save_file: "/home/seventheli/logging/"
  score: 400
  min_time: 180000
  max_time: 216000
  log: 5
  save: 100